---
title: "DeepMind Teaches AI When to Be Creative and When to Be Literal"
description: "New research addresses one of AI's most persistent problems: knowing when creative interpretation helps versus when strict accuracy is required."
publishedAt: "2026-01-25"
author: "Jo's Daily Digests"
category: "AI"
tags: ["DeepMind", "AI Safety", "Hallucination", "Research", "Epistemic Modes"]
source:
  channel: "Dylan Curious"
  handle: "dylan_curious"
  videoId: "bXHkbA3kFAY"
  videoTitle: "The Most Disturbing Week in AI"
---

A new research paper from Google DeepMind addresses one of the most persistent practical problems in deploying AI systems: how to make models that know when creative interpretation is appropriate and when strict literalism is required.

The problem is familiar to anyone who has used modern AI assistants. Ask an AI to write a poem about love, and creative license is desirable. But ask the same AI to calculate medication dosages, and even small creative interpretations could be catastrophic.

## The 2+2=5 Problem

DeepMind's solution involves training AI systems to explicitly recognize the "epistemic mode" required for different types of queries. The training process included carefully constructed test cases, including the mathematical statement "2 + 2 = 5."

In most contexts, an AI system should recognize this as false. But creative contexts exist where the statement makes sense—an essay about Orwellian totalitarianism, a discussion of non-Euclidean mathematics, or a meditation on the nature of truth.

"They've taught it that's not just emerging from knowledge like it is in ChatGPT or Gemini," Dylan Curious observed. "That's an actual learned thing."

## Critical Infrastructure Implications

The research has significant implications for deploying AI in high-stakes environments. Critical infrastructure systems—power grids, bridges, medical devices—cannot tolerate creative hallucination.

"There are so many systems where we really can't afford a creative answer that breaks reality," Dylan Curious noted. "We still want an AI that's flexible but not reckless."

## Bottom Line

The DeepMind researchers report that their approach significantly reduces inappropriate hallucination in precision-critical contexts while preserving creative capability where it's desired. This could be a crucial step toward deploying AI safely in environments where errors have real consequences.
