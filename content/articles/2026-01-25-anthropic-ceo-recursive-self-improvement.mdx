---
title: "Anthropic CEO: Recursive Self-Improvement Could Be Six Months Away"
description: "At Davos, Dario Amodei dropped a bombshell — claiming AI systems improving themselves without human intervention could arrive within months. Claude is already helping build its successor."
publishedAt: "2026-01-25"
author: "Jo's Daily Digests"
category: "AI"
tags: ["Anthropic", "AGI", "Davos", "Recursive Self-Improvement", "Claude"]
source:
  channel: "David Shapiro"
  handle: "DaveShap"
  videoId: "WNU078Hwgqs"
  videoTitle: "Dario Amodei (Anthropic) Drops ATOMIC BOMBSHELL at Davos!"
---

At the World Economic Forum in Davos this week, Anthropic CEO Dario Amodei made what may be the most significant public statement yet from an AI lab leader about the proximity of artificial general intelligence. In a brief but explosive interview clip that quickly circulated across social media, Amodei claimed that fully automated recursive self-improvement—the point at which AI systems can improve themselves without human intervention—could be just six to twelve months away.

"This is not some random person on Twitter making bold predictions," David Shapiro emphasized in his reaction. "This is the CEO of one of the top three frontier AI labs in the world, speaking at Davos, telling the global elite that we could be less than a year away from machines that can recursively improve themselves."

## Claude Is Already Building Its Successor

Amodei's most striking revelation concerned the current state of AI-assisted development at Anthropic itself. According to the CEO, some researchers working on the next generation of Claude are now having AI write "pretty much 100% of the code" for them. This represents a dramatic acceleration from even six months ago, when AI coding assistants were primarily used for boilerplate and simple functions rather than core research infrastructure.

The implications are profound: Claude is, in effect, already helping to build its successor. The feedback loop that researchers have long theorized about—where AI systems contribute meaningfully to their own improvement—appears to have quietly begun.

## DeepMind's "Chief AGI Economist" Signals Industry-Wide Preparation

Shapiro connected Amodei's remarks to another development that flew under the radar this week: Google DeepMind has posted a job listing for a "Chief AGI Economist," a position that would be responsible for analyzing and preparing for the economic implications of artificial general intelligence.

"When DeepMind—one of the most conservative labs in terms of public AGI timelines—starts hiring economists specifically to plan for a post-AGI world, that tells you something," Shapiro observed. "They're not hiring this person to write theoretical papers. They're hiring them because they believe they'll need this expertise in the near term."

## Convergence of Signals

The third data point comes from Elon Musk's AI venture, xAI. Musk has explicitly stated that xAI's goal by the end of 2026 is to have AI systems capable of performing as "smarter than human workers" across a broad range of cognitive tasks.

"When you have Anthropic, DeepMind, and xAI all converging on the same approximate timeline, that's not coincidence," Shapiro noted. "That's coordination around shared private knowledge about where the technology actually is."

## The Energy Economics Argument

Beyond pure capability arguments, Shapiro devoted significant analysis to what he calls the "thermodynamic inevitability" of AI labor replacement. Drawing on research showing that modern food production requires approximately ten calories of economic input to produce one calorie of human nutrition, plus housing, transportation, and healthcare costs, the total energy budget for human cognitive labor is enormous.

AI systems, by contrast, can be powered directly by solar farms co-located with data centers, creating a "self-contained loop" with dramatically higher efficiency. As solar technology improves, the energy cost per unit of AI cognition continues to fall, while human cognition costs remain relatively fixed.

## Human Labor May Soon Have "Negative Expected Value"

Perhaps the most provocative claim concerns the future trajectory of human labor value. At some point, humans become "too many cooks in the kitchen"—their coordination costs exceed their marginal contribution to research efforts.

"Eventually, the money and energy that you spend on those hundred researchers might be better suited to just giving the AI more time and more compute," Shapiro explained. "Before too long, human judgment, human intuition, human intelligence will be negative EV."

## Bottom Line

The convergence of signals from Anthropic, DeepMind, and xAI points to a shared private assessment among frontier AI labs: recursive self-improvement capabilities are close, possibly within a year. The economic and thermodynamic arguments for AI labor replacement are becoming harder to dismiss.

"This is the clearest signal yet that the labs believe we're close," Shapiro concluded. "When Dario Amodei goes to Davos and tells the world's elite that AI is already writing the code for its own successor, we should take that seriously."
